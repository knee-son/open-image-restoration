{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import numpy as np\n",
    "import time\n",
    "import ImagePipeline_utils as IP\n",
    "from ImagePipeline_utils import timing, suppress_stdout\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "print(base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/mickael.tits/image-restoration'\n",
    "\n",
    "\n",
    "\n",
    "#in google colab, simply use:\n",
    "#base_dir = '/content'\n",
    "\n",
    "os.chdir(base_dir)\n",
    "\n",
    "input_dir = path.join(base_dir, 'MyImages')\n",
    "output_dir = path.join(base_dir, 'MyResults')\n",
    "\n",
    "if not path.exists(input_dir):\n",
    "    os.makedirs(input_dir)\n",
    "    \n",
    "if not path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "#needed to use the right python interpreter when calling command line from jupyter (there should be a better solution but I did not figure it yet)\n",
    "python_dir = '/home/mickael.tits/miniconda/envs/imagepipeline/bin/python'\n",
    "#in colab, simply use:\n",
    "#python_dir = 'python'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare inputs/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "Eo1STXdhM0mI",
    "outputId": "c78c5e44-9fe3-485d-e095-6a60f26e3e55"
   },
   "outputs": [],
   "source": [
    "# Create or reset input directory\n",
    "\n",
    "!rm -r {input_dir}\n",
    "!mkdir {input_dir}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "yzdfOh30O_Oa",
    "outputId": "fdcb69ec-89ce-4f50-e7b4-ddba302d374b"
   },
   "outputs": [],
   "source": [
    "\n",
    "!rm -r {output_dir}\n",
    "!mkdir {output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if thare are images in input_dir\n",
    "\n",
    "if not os.listdir(input_dir):\n",
    "    raise Exception(\"Input directory is empty. No images to process.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#grayscale needed for NLRN (it takes only one channel)\n",
    "convert_to_grayscale = True\n",
    "resize_images = True\n",
    "size = 1000,1000\n",
    "    \n",
    "IP.preprocess(input_dir, size=size, gray = convert_to_grayscale, resize = resize_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising - NLRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mickael.tits/image-restoration\n",
      "rm: cannot remove '/home/mickael.tits/image-restoration/MyImages/.ipynb_checkpoints': No such file or directory\n",
      "mkdir: cannot create directory ‘/home/mickael.tits/image-restoration/MyResults/NLRN’: File exists\n",
      "Model files missing, let's download them...\n",
      "rm: cannot remove 'sigma15_12states.zip': No such file or directory\n",
      "rm: cannot remove 'sigma15': No such file or directory\n",
      "--2019-07-23 09:29:10--  https://docs.google.com/uc?export=download&id=1cbaLYjPn_H6TRbLPfA6B3j45TmKdUrfa\n",
      "Resolving docs.google.com (docs.google.com)... 108.177.126.139, 108.177.126.113, 108.177.126.102, ...\n",
      "Connecting to docs.google.com (docs.google.com)|108.177.126.139|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-0k-7g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bgclpkoegvgek2pcv2bia2a4qgns6k5m/1563868800000/05497926257477138925/*/1cbaLYjPn_H6TRbLPfA6B3j45TmKdUrfa?e=download [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2019-07-23 09:29:10--  https://doc-0k-7g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bgclpkoegvgek2pcv2bia2a4qgns6k5m/1563868800000/05497926257477138925/*/1cbaLYjPn_H6TRbLPfA6B3j45TmKdUrfa?e=download\n",
      "Resolving doc-0k-7g-docs.googleusercontent.com (doc-0k-7g-docs.googleusercontent.com)... 173.194.79.132, 2a00:1450:4013:c05::84\n",
      "Connecting to doc-0k-7g-docs.googleusercontent.com (doc-0k-7g-docs.googleusercontent.com)|173.194.79.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1347613 (1.3M) [application/zip]\n",
      "Saving to: ‘sigma15_12states.zip’\n",
      "\n",
      "sigma15_12states.zi 100%[===================>]   1.29M  --.-KB/s    in 0.009s  \n",
      "\n",
      "2019-07-23 09:29:10 (144 MB/s) - ‘sigma15_12states.zip’ saved [1347613/1347613]\n",
      "\n",
      "Archive:  sigma15_12states.zip\n",
      "   creating: sigma15/\n",
      "  inflating: sigma15/saved_model.pb  \n",
      "   creating: sigma15/variables/\n",
      "  inflating: sigma15/variables/variables.data-00000-of-00001  \n",
      "  inflating: sigma15/variables/variables.index  \n",
      "2019-07-23 09:29:10.837490: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2019-07-23 09:29:10.843038: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000155000 Hz\n",
      "2019-07-23 09:29:10.843424: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5631a8e4fde0 executing computations on platform Host. Devices:\n",
      "2019-07-23 09:29:10.843461: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-23 09:29:11.003056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-23 09:29:11.003797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 14.73GiB freeMemory: 14.62GiB\n",
      "2019-07-23 09:29:11.003834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-07-23 09:29:11.004664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-07-23 09:29:11.004711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-07-23 09:29:11.004717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-07-23 09:29:11.004819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "2019-07-23 09:29:11.006853: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5631a9f966d0 executing computations on platform CUDA. Devices:\n",
      "2019-07-23 09:29:11.006892: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "WARNING:tensorflow:From /home/mickael.tits/image-restoration/denoiser.py:26: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/mickael.tits/miniconda/envs/imagepipeline/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "NLRN Model loaded...\n",
      "2019-07-23 09:29:14.282327: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "CETIC 2 (887).png: finished in 23.6179 s\n",
      "Denoising - NLRN: finished in 23.6180 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dn_input_dir = input_dir\n",
    "\n",
    "dn_method = 'NLRN'\n",
    "\n",
    "#dn_working_dir = path.join(base_dir,dn_method)\n",
    "dn_output_dir = path.join(output_dir, dn_method)\n",
    "\n",
    "os.chdir(base_dir)\n",
    "\n",
    "!rm -r {dn_input_dir}'/.ipynb_checkpoints'\n",
    "!mkdir {dn_output_dir}\n",
    "\n",
    "!{python_dir} denoiser.py -i {dn_input_dir} -o {dn_output_dir}\n",
    "\n",
    "#!{python_dir} {base_dir}'/denoiser_NLRN_DNCNN.py' --method 'NLRN' --input-dir {dn_input_dir} --output-dir {dn_output_dir}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorization - NoGAN (DeOldify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/mickael.tits/image-restoration/MyResults/DeOldify’: File exists\n",
      "/home/mickael.tits/miniconda/envs/imagepipeline/lib/python3.6/site-packages/fastai/data_block.py:451: UserWarning: Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\n",
      "  warn(\"Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\")\n",
      "/home/mickael.tits/miniconda/envs/imagepipeline/lib/python3.6/site-packages/fastai/data_block.py:454: UserWarning: Your validation set is empty. If this is by design, use `split_none()`\n",
      "                 or pass `ignore_empty=True` when labelling to remove this warning.\n",
      "  or pass `ignore_empty=True` when labelling to remove this warning.\"\"\")\n",
      "1. CETIC 2 (887).png: finished in 8.0966 s\n",
      "Colorization: finished in 8.0967 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col_input_dir = dn_output_dir\n",
    "#col_working_dir = path.join(base_dir, 'DeOldify')\n",
    "col_output_dir = path.join(output_dir, 'DeOldify')\n",
    "\n",
    "!mkdir {col_output_dir}\n",
    "\n",
    "os.chdir(base_dir)\n",
    "\n",
    "!{python_dir} colorizer.py -i {col_input_dir} -o {col_output_dir}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super-resolution - ESRGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path ./ESRGAN/models/RRDB_PSNR_x4.pth. \n",
      "Testing...\n",
      "1 CETIC 2 (887)\n",
      "super-resolution: finished in 2.1117 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sr_input_dir = col_output_dir\n",
    "\n",
    "sr_output_dir = path.join(output_dir, 'ESRGAN_PSNR')\n",
    "\n",
    "!mkdir {sr_output_dir}\n",
    "\n",
    "os.chdir(base_dir)\n",
    "\n",
    "!{python_dir} superresolution.py -i {sr_input_dir} -o {sr_output_dir} -a 'PSNR'\n",
    "#-a 'PSNR'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {base_dir}\n",
    "!zip -r outputs.zip {output_dir}\n",
    "!zip -r final.zip {sr_output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental: image enhancement (calling other conda environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mickael.tits/Deep-Photo-Enhance/LPGAN_exp_G3_999\n",
      "mkdir: cannot create directory ‘enh_output_dir’: File exists\n",
      "I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\n",
      "I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \n",
      "name: Tesla T4\n",
      "major: 7 minor: 5 memoryClockRate (GHz) 1.59\n",
      "pciBusID 0000:00:04.0\n",
      "Total memory: 14.73GiB\n",
      "Free memory: 14.62GiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mickael.tits/Deep-Photo-Enhance/LPGAN_exp_G3_999/deep-photo-enhancer.py\", line 215, in <module>\n",
      "    enhance()\n",
      "  File \"/home/mickael.tits/Deep-Photo-Enhance/LPGAN_exp_G3_999/deep-photo-enhancer.py\", line 204, in enhance\n",
      "    orignames = glob.glob(os.path.join(input_dir, '*'))\n",
      "NameError: global name 'input_dir' is not defined\n"
     ]
    }
   ],
   "source": [
    "python_dir2 = '/home/mickael.tits/miniconda/envs/dpenhance/bin/python'\n",
    "base_dir = '/home/mickael.tits/Deep-Photo-Enhance/'\n",
    "\n",
    "working_dir = base_dir + 'LPGAN_exp_G3_999/'\n",
    "\n",
    "%cd {working_dir}\n",
    "\n",
    "script_path = os.path.join(working_dir ,'deep-photo-enhancer.py' )\n",
    "\n",
    "model_dir =  os.path.join(base_dir, 'LPGAN_exp_G3_999/', 'model/90.000-new.ckpt')\n",
    "\n",
    "enh_input_dir = col_output_dir\n",
    "\n",
    "enh_output_dir =  os.path.join(base_dir, 'MyResults/')\n",
    "\n",
    "!mkdir enh_output_dir\n",
    "\n",
    "!{python_dir2} {script_path} --model-path {model_dir} --input-dir {enh_input_dir} --output-dir {enh_output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagepipeline",
   "language": "python",
   "name": "imagepipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
