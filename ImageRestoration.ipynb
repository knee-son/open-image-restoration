{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import numpy as np\n",
    "import time\n",
    "import ImagePipeline_utils as IP\n",
    "from ImagePipeline_utils import timing, suppress_stdout\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "print(base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/mickael.tits/image-restoration-github'\n",
    "\n",
    "\n",
    "\n",
    "#in google colab, simply use:\n",
    "#base_dir = '/content'\n",
    "\n",
    "os.chdir(base_dir)\n",
    "\n",
    "input_dir = path.join(base_dir, 'MyImages')\n",
    "output_dir = path.join(base_dir, 'MyResults')\n",
    "\n",
    "if not path.exists(input_dir):\n",
    "    os.makedirs(input_dir)\n",
    "    \n",
    "if not path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "#needed to use the right python interpreter when calling command line from jupyter (there should be a better solution but I did not figure it yet)\n",
    "python_dir = '/home/mickael.tits/miniconda/envs/imagepipeline/bin/python'\n",
    "#in colab, simply use:\n",
    "#python_dir = 'python'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare inputs/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "Eo1STXdhM0mI",
    "outputId": "c78c5e44-9fe3-485d-e095-6a60f26e3e55"
   },
   "outputs": [],
   "source": [
    "# Create or reset input directory\n",
    "\n",
    "!rm -r {input_dir}\n",
    "!mkdir {input_dir}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "yzdfOh30O_Oa",
    "outputId": "fdcb69ec-89ce-4f50-e7b4-ddba302d374b"
   },
   "outputs": [],
   "source": [
    "\n",
    "!rm -r {output_dir}\n",
    "!mkdir {output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if thare are images in input_dir\n",
    "\n",
    "if not os.listdir(input_dir):\n",
    "    raise Exception(\"Input directory is empty. No images to process.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot identify image file '/home/mickael.tits/image-restoration-github/MyImages/Thumbs.db'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#grayscale needed for NLRN (it takes only one channel)\n",
    "convert_to_grayscale = True\n",
    "resize_images = True\n",
    "size = 1000,1000\n",
    "    \n",
    "IP.preprocess(input_dir, size=size, gray = convert_to_grayscale, resize = resize_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising - NLRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/home/mickael.tits/image-restoration-github/MyImages/.ipynb_checkpoints': No such file or directory\n",
      "2019-09-16 08:15:41.288462: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2019-09-16 08:15:41.809503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000125000 Hz\n",
      "2019-09-16 08:15:41.832720: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55fc5bc38e80 executing computations on platform Host. Devices:\n",
      "2019-09-16 08:15:41.832812: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-09-16 08:15:42.888222: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2019-09-16 08:15:42.888283: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: instance-1-deep-learning-25085\n",
      "2019-09-16 08:15:42.888304: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: instance-1-deep-learning-25085\n",
      "2019-09-16 08:15:42.888386: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:192] libcuda reported version is: 418.67.0\n",
      "2019-09-16 08:15:42.888423: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:196] kernel reported version is: 418.67.0\n",
      "2019-09-16 08:15:42.888434: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:303] kernel version seems to match DSO: 418.67.0\n",
      "WARNING:tensorflow:From denoiser.py:37: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/mickael.tits/miniconda/envs/imagepipeline/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "NLRN Model loaded...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dn_input_dir = input_dir\n",
    "\n",
    "dn_method = 'NLRN'\n",
    "\n",
    "#dn_working_dir = path.join(base_dir,dn_method)\n",
    "dn_output_dir = path.join(output_dir, dn_method)\n",
    "\n",
    "os.chdir(base_dir)\n",
    "\n",
    "!rm -r {dn_input_dir}'/.ipynb_checkpoints'\n",
    "!mkdir {dn_output_dir}\n",
    "\n",
    "!{python_dir} denoiser.py -i {dn_input_dir} -o {dn_output_dir}\n",
    "\n",
    "#!{python_dir} {base_dir}'/denoiser_NLRN_DNCNN.py' --method 'NLRN' --input-dir {dn_input_dir} --output-dir {dn_output_dir}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-be24a1d925b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' denoiser.py -i '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdn_input_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' -o '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdn_output_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#!{python_dir} denoiser.py -i {dn_input_dir} -o {dn_output_dir}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/imagepipeline/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/imagepipeline/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout, endtime)\u001b[0m\n\u001b[1;32m   1455\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/imagepipeline/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1402\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1404\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1405\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "command = python_dir + ' denoiser.py -i ' + dn_input_dir + ' -o ' + dn_output_dir\n",
    "proc = subprocess.call(command, shell=True)\n",
    "\n",
    "#!{python_dir} denoiser.py -i {dn_input_dir} -o {dn_output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorization - NoGAN (DeOldify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/mickael.tits/image-restoration/MyResults/DeOldify’: File exists\n",
      "/home/mickael.tits/miniconda/envs/imagepipeline/lib/python3.6/site-packages/fastai/data_block.py:451: UserWarning: Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\n",
      "  warn(\"Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\")\n",
      "/home/mickael.tits/miniconda/envs/imagepipeline/lib/python3.6/site-packages/fastai/data_block.py:454: UserWarning: Your validation set is empty. If this is by design, use `split_none()`\n",
      "                 or pass `ignore_empty=True` when labelling to remove this warning.\n",
      "  or pass `ignore_empty=True` when labelling to remove this warning.\"\"\")\n",
      "1. CETIC 2 (887).png: finished in 8.0966 s\n",
      "Colorization: finished in 8.0967 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col_input_dir = dn_output_dir\n",
    "#col_working_dir = path.join(base_dir, 'DeOldify')\n",
    "col_output_dir = path.join(output_dir, 'DeOldify')\n",
    "\n",
    "!mkdir {col_output_dir}\n",
    "\n",
    "os.chdir(base_dir)\n",
    "\n",
    "!{python_dir} colorizer.py -i {col_input_dir} -o {col_output_dir}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super-resolution - ESRGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path ./ESRGAN/models/RRDB_PSNR_x4.pth. \n",
      "Testing...\n",
      "1 CETIC 2 (887)\n",
      "super-resolution: finished in 2.1117 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sr_input_dir = col_output_dir\n",
    "\n",
    "sr_output_dir = path.join(output_dir, 'ESRGAN_PSNR')\n",
    "\n",
    "!mkdir {sr_output_dir}\n",
    "\n",
    "os.chdir(base_dir)\n",
    "\n",
    "!{python_dir} superresolution.py -i {sr_input_dir} -o {sr_output_dir} -a 'PSNR'\n",
    "#-a 'PSNR'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {base_dir}\n",
    "!zip -r outputs.zip {output_dir}\n",
    "!zip -r final.zip {sr_output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental: image enhancement (calling other conda environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mickael.tits/Deep-Photo-Enhance/LPGAN_exp_G3_999\n",
      "mkdir: cannot create directory ‘enh_output_dir’: File exists\n",
      "I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\n",
      "I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \n",
      "name: Tesla T4\n",
      "major: 7 minor: 5 memoryClockRate (GHz) 1.59\n",
      "pciBusID 0000:00:04.0\n",
      "Total memory: 14.73GiB\n",
      "Free memory: 14.62GiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mickael.tits/Deep-Photo-Enhance/LPGAN_exp_G3_999/deep-photo-enhancer.py\", line 215, in <module>\n",
      "    enhance()\n",
      "  File \"/home/mickael.tits/Deep-Photo-Enhance/LPGAN_exp_G3_999/deep-photo-enhancer.py\", line 204, in enhance\n",
      "    orignames = glob.glob(os.path.join(input_dir, '*'))\n",
      "NameError: global name 'input_dir' is not defined\n"
     ]
    }
   ],
   "source": [
    "python_dir2 = '/home/mickael.tits/miniconda/envs/dpenhance/bin/python'\n",
    "base_dir = '/home/mickael.tits/Deep-Photo-Enhance/'\n",
    "\n",
    "working_dir = base_dir + 'LPGAN_exp_G3_999/'\n",
    "\n",
    "%cd {working_dir}\n",
    "\n",
    "script_path = os.path.join(working_dir ,'deep-photo-enhancer.py' )\n",
    "\n",
    "model_dir =  os.path.join(base_dir, 'LPGAN_exp_G3_999/', 'model/90.000-new.ckpt')\n",
    "\n",
    "enh_input_dir = col_output_dir\n",
    "\n",
    "enh_output_dir =  os.path.join(base_dir, 'MyResults/')\n",
    "\n",
    "!mkdir enh_output_dir\n",
    "\n",
    "!{python_dir2} {script_path} --model-path {model_dir} --input-dir {enh_input_dir} --output-dir {enh_output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagepipeline",
   "language": "python",
   "name": "imagepipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
